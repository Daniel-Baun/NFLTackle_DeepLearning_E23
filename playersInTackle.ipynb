{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import math\n",
    "import datetime\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the play_data and tackles_data from CSV files\n",
    "play_data = pd.read_csv('data/plays.csv')\n",
    "tackles_data = pd.read_csv('data/tackles.csv')\n",
    "\n",
    "# Group play_data by 'gameId'\n",
    "grouped_play_data = play_data.groupby('gameId')\n",
    "\n",
    "# Initialize an empty dictionary to store DataFrames for each game\n",
    "game_data_dict = {}\n",
    "\n",
    "# Iterate through each group (each unique gameId)\n",
    "for game_id, play_group in grouped_play_data:\n",
    "    # Filter the tackles data for the current 'gameId'\n",
    "    tackles_for_game = tackles_data[tackles_data['gameId'] == game_id]\n",
    "    \n",
    "    # Get the playIds corresponding to tackles in this game\n",
    "    tackle_playIds = tackles_for_game['playId'].unique()\n",
    "    \n",
    "    # Filter the play_group to keep only playIds corresponding to tackles\n",
    "    filtered_play_group = play_group[play_group['playId'].isin(tackle_playIds)]\n",
    "    \n",
    "    # Store the filtered play data for the current game in the dictionary\n",
    "    game_data_dict[game_id] = filtered_play_group\n",
    "\n",
    "# Now, 'game_data_dict' contains DataFrames for each unique 'gameId' with only tackle plays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           gameId  playId  ballCarrierId ballCarrierDisplayName  \\\n",
      "209    2022090800    2184          42489           Stefon Diggs   \n",
      "262    2022090800    2307          44881            Cooper Kupp   \n",
      "578    2022090800    3304          52494              Zack Moss   \n",
      "1131   2022090800    2648          46076             Josh Allen   \n",
      "1401   2022090800    2336          47853      Darrell Henderson   \n",
      "...           ...     ...            ...                    ...   \n",
      "11576  2022090800     393          47853      Darrell Henderson   \n",
      "11580  2022090800    3431          53678          Ben Skowronek   \n",
      "11953  2022090800     646          47879            Dawson Knox   \n",
      "12048  2022090800    1286          44881            Cooper Kupp   \n",
      "12206  2022090800     896          54528             James Cook   \n",
      "\n",
      "                                         playDescription  quarter  down  \\\n",
      "209    (9:24) (Shotgun) J.Allen pass short left to S....        3     1   \n",
      "262    (7:28) (Shotgun) M.Stafford pass deep left to ...        3     2   \n",
      "578    (5:27) Z.Moss left tackle to LA 16 for 4 yards...        4     2   \n",
      "1131   (:33) (Shotgun) J.Allen up the middle to BUF 4...        3     2   \n",
      "1401   (7:02) (No Huddle) M.Stafford pass short middl...        3     1   \n",
      "...                                                  ...      ...   ...   \n",
      "11576  (7:45) (Shotgun) D.Henderson right guard to LA...        1     1   \n",
      "11580  (3:41) (No Huddle, Shotgun) M.Stafford pass sh...        4     2   \n",
      "11953  (1:53) J.Allen pass short left to D.Knox to LA...        1     1   \n",
      "12048  (6:49) M.Stafford pass short left to C.Kupp pu...        2     1   \n",
      "12206  (13:36) (Shotgun) J.Cook right tackle to BUF 3...        2     2   \n",
      "\n",
      "       yardsToGo possessionTeam defensiveTeam  ...  \\\n",
      "209           10            BUF            LA  ...   \n",
      "262           10             LA           BUF  ...   \n",
      "578            6            BUF            LA  ...   \n",
      "1131          10            BUF            LA  ...   \n",
      "1401          10             LA           BUF  ...   \n",
      "...          ...            ...           ...  ...   \n",
      "11576         10             LA           BUF  ...   \n",
      "11580          4             LA           BUF  ...   \n",
      "11953         10            BUF            LA  ...   \n",
      "12048         10             LA           BUF  ...   \n",
      "12206          8            BUF            LA  ...   \n",
      "\n",
      "      preSnapHomeTeamWinProbability  preSnapVisitorTeamWinProbability  \\\n",
      "209                        0.324996                          0.675004   \n",
      "262                        0.230606                          0.769394   \n",
      "578                        0.001397                          0.998603   \n",
      "1131                       0.134761                          0.865239   \n",
      "1401                       0.273965                          0.726035   \n",
      "...                             ...                               ...   \n",
      "11576                      0.314065                          0.685935   \n",
      "11580                      0.002557                          0.997443   \n",
      "11953                      0.204260                          0.795740   \n",
      "12048                      0.235913                          0.764087   \n",
      "12206                      0.225668                          0.774332   \n",
      "\n",
      "      homeTeamWinProbabilityAdded  visitorTeamWinProbilityAdded  \\\n",
      "209                     -0.013726                      0.013726   \n",
      "262                      0.043359                     -0.043359   \n",
      "578                      0.001232                     -0.001232   \n",
      "1131                     0.015617                     -0.015617   \n",
      "1401                     0.008647                     -0.008647   \n",
      "...                           ...                           ...   \n",
      "11576                   -0.015263                      0.015263   \n",
      "11580                   -0.000063                      0.000063   \n",
      "11953                   -0.029484                      0.029484   \n",
      "12048                    0.007502                     -0.007502   \n",
      "12206                    0.094656                     -0.094656   \n",
      "\n",
      "       expectedPoints expectedPointsAdded            foulName1  foulName2  \\\n",
      "209          4.730500            0.406682                  NaN        NaN   \n",
      "262          0.805026            2.080663                  NaN        NaN   \n",
      "578          4.320043           -4.856559                  NaN        NaN   \n",
      "1131         2.036072           -0.828860                  NaN        NaN   \n",
      "1401         2.885689            0.513975                  NaN        NaN   \n",
      "...               ...                 ...                  ...        ...   \n",
      "11576        2.458136           -0.386335                  NaN        NaN   \n",
      "11580        1.420936            0.693287                  NaN        NaN   \n",
      "11953        2.706385            1.352469  Horse Collar Tackle        NaN   \n",
      "12048        3.667560            0.273790                  NaN        NaN   \n",
      "12206        1.077905           -4.717964                  NaN        NaN   \n",
      "\n",
      "       foulNFLId1  foulNFLId2  \n",
      "209           NaN         NaN  \n",
      "262           NaN         NaN  \n",
      "578           NaN         NaN  \n",
      "1131          NaN         NaN  \n",
      "1401          NaN         NaN  \n",
      "...           ...         ...  \n",
      "11576         NaN         NaN  \n",
      "11580         NaN         NaN  \n",
      "11953     47939.0         NaN  \n",
      "12048         NaN         NaN  \n",
      "12206         NaN         NaN  \n",
      "\n",
      "[87 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already created the 'game_data_dict' dictionary as mentioned before\n",
    "\n",
    "# Specify the 'gameId' of the game you want to print tackles for\n",
    "target_game_id = 2022090800  # Replace with the actual 'gameId' you're interested in\n",
    "\n",
    "# Check if the 'gameId' is in the dictionary\n",
    "if target_game_id in game_data_dict:\n",
    "    # Get the DataFrame for the specified game\n",
    "    game_df = game_data_dict[target_game_id]\n",
    "    \n",
    "    # Print the DataFrame containing the tackles for the game\n",
    "    print(game_df)\n",
    "else:\n",
    "    print(f\"Game with 'gameId' {target_game_id} not found in the dictionary.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of plays with at least one tackle: 3776\n",
      "Number of plays with only pff_missedTackle (no tackles): 1423\n"
     ]
    }
   ],
   "source": [
    "# Filter the tackles data to include plays with at least one tackle\n",
    "plays_with_tackle = tackles_data[tackles_data['tackle'] == 1]\n",
    "\n",
    "# Filter the tackles data to include plays with only pff_missedTackle (no tackles)\n",
    "plays_with_missed_tackle = tackles_data[(tackles_data['pff_missedTackle'] == 1) & (tackles_data['tackle'] == 0)]\n",
    "\n",
    "# Count the unique 'playId' values in each filtered data\n",
    "count_plays_with_tackle = len(plays_with_tackle['playId'].unique())\n",
    "count_plays_with_missed_tackle = len(plays_with_missed_tackle['playId'].unique())\n",
    "\n",
    "# Print the counts\n",
    "print(f\"Number of plays with at least one tackle: {count_plays_with_tackle}\")\n",
    "print(f\"Number of plays with only pff_missedTackle (no tackles): {count_plays_with_missed_tackle}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataframes for each tracking_week_x.csv\n",
    "path = 'data/tracking_week_*.csv'\n",
    "all_files = glob.glob(path)\n",
    "li = []\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "tracking_data = pd.concat(li, axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       gameId  playId    nflId     displayName  frameId  \\\n",
      "0  2022090800      56  35472.0  Rodger Saffold        1   \n",
      "1  2022090800      56  35472.0  Rodger Saffold        2   \n",
      "2  2022090800      56  35472.0  Rodger Saffold        3   \n",
      "3  2022090800      56  35472.0  Rodger Saffold        4   \n",
      "4  2022090800      56  35472.0  Rodger Saffold        5   \n",
      "\n",
      "                         time  jerseyNumber club playDirection      x      y  \\\n",
      "0  2022-09-08 20:24:05.200000          76.0  BUF          left  88.37  27.27   \n",
      "1  2022-09-08 20:24:05.299999          76.0  BUF          left  88.47  27.13   \n",
      "2  2022-09-08 20:24:05.400000          76.0  BUF          left  88.56  27.01   \n",
      "3  2022-09-08 20:24:05.500000          76.0  BUF          left  88.64  26.90   \n",
      "4  2022-09-08 20:24:05.599999          76.0  BUF          left  88.72  26.80   \n",
      "\n",
      "      s     a   dis       o     dir         event  \n",
      "0  1.62  1.15  0.16  231.74  147.90           NaN  \n",
      "1  1.67  0.61  0.17  230.98  148.53  pass_arrived  \n",
      "2  1.57  0.49  0.15  230.98  147.05           NaN  \n",
      "3  1.44  0.89  0.14  232.38  145.42           NaN  \n",
      "4  1.29  1.24  0.13  233.36  141.95           NaN  \n"
     ]
    }
   ],
   "source": [
    "print(tracking_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            time                  game_time\n",
      "0     2022-09-08 20:24:05.200000 2022-09-08 20:24:05.200000\n",
      "1     2022-09-08 20:24:05.299999 2022-09-08 20:24:05.299999\n",
      "2     2022-09-08 20:24:05.400000 2022-09-08 20:24:05.400000\n",
      "3     2022-09-08 20:24:05.500000 2022-09-08 20:24:05.500000\n",
      "4     2022-09-08 20:24:05.599999 2022-09-08 20:24:05.599999\n",
      "...                          ...                        ...\n",
      "70290 2022-09-08 22:53:34.599999 2022-09-08 22:53:34.599999\n",
      "70291 2022-09-08 22:53:34.700000 2022-09-08 22:53:34.700000\n",
      "70292 2022-09-08 22:53:34.799999 2022-09-08 22:53:34.799999\n",
      "70293 2022-09-08 22:53:34.900000 2022-09-08 22:53:34.900000\n",
      "70294 2022-09-08 22:53:35.000000 2022-09-08 22:53:35.000000\n",
      "\n",
      "[1698 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the tracking data for week 1 into a DataFrame\n",
    "tracking_data = pd.read_csv('data/tracking_week_1.csv')\n",
    "\n",
    "# Filter the tracking data for nflId 35472\n",
    "player_data = tracking_data[tracking_data['nflId'] == 35472]\n",
    "\n",
    "# Convert the timestamp to a datetime object\n",
    "player_data['time'] = pd.to_datetime(player_data['time'])\n",
    "\n",
    "# Define the game start time for week 1 (replace with the actual start time)\n",
    "game_start_time = pd.Timestamp(str(player_data['time'].iloc[0]))\n",
    "\n",
    "# Calculate the game time for each tracking data point\n",
    "player_data['game_time'] = game_start_time + (player_data['time'] - player_data['time'].iloc[0])\n",
    "\n",
    "# Now, the 'game_time' column in player_data represents the game time\n",
    "print(player_data[['time', 'game_time']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3430\n",
      "Total missed tackles: 1763\n",
      "Total tackles: 1374\n",
      "       gameId  playId  count  nflId  tackle  assist  forcedFumble  \\\n",
      "0  2022090800    1102      2  42816       1       0             0   \n",
      "1  2022090800    1102      2  52492       0       0             0   \n",
      "2  2022090800    1385      3  52647       1       0             0   \n",
      "3  2022090800    1385      3  46085       0       1             0   \n",
      "4  2022090800    1385      3  46232       0       0             0   \n",
      "\n",
      "   pff_missedTackle  \n",
      "0                 0  \n",
      "1                 1  \n",
      "2                 0  \n",
      "3                 0  \n",
      "4                 1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have already loaded the tackles data into a DataFrame named 'tackles_data'\n",
    "tackles_data = pd.read_csv('data/tackles.csv')\n",
    "# Filter the tackles data to include plays with tackles or missed tackles\n",
    "tackle_missed_tackle_data = tackles_data[(tackles_data['tackle'] == 1) | (tackles_data['pff_missedTackle'] == 1)]\n",
    "\n",
    "# Group the filtered data by 'gameId' and 'playId' and count the number of unique occurrences\n",
    "unique_combinations = tackle_missed_tackle_data.groupby(['gameId', 'playId']).size().reset_index(name='count')\n",
    "\n",
    "# Filter the unique combinations to include only those where count is greater than 1\n",
    "unique_combinations = unique_combinations[unique_combinations['count'] > 1]\n",
    "\n",
    "# Merge the filtered combinations with the original tackles data to get the desired rows\n",
    "result = pd.merge(unique_combinations, tackles_data, on=['gameId', 'playId'], how='inner')\n",
    "\n",
    "# Now, 'result' contains every tackle where gameId and playId combinations are unique\n",
    "# and there is either a tackle=1 or pff_missedTackle=1 (excluding plays with only assist=1)\n",
    "print(len(result))\n",
    "#total missed tackles\n",
    "total_missed_tackles = len(result[result['pff_missedTackle'] == 1])\n",
    "print(f\"Total missed tackles: {total_missed_tackles}\")\n",
    "#total tackles\n",
    "total_tackles = len(result[result['tackle'] == 1])\n",
    "print(f\"Total tackles: {total_tackles}\")\n",
    "print(result.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "661\n",
      "1022\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the \"players.csv\" file into a DataFrame\n",
    "players_data = pd.read_csv('data/players.csv')\n",
    "\n",
    "# Create a list of unique NFL IDs for players involved in a tackle\n",
    "tackle_nfl_ids = result['nflId'].unique()\n",
    "\n",
    "# Filter the players DataFrame to include only players involved in a tackle\n",
    "tackling_players = players_data[players_data['nflId'].isin(tackle_nfl_ids)]\n",
    "\n",
    "# Filter the players DataFrame to include only players not involved in a tackle\n",
    "non_tackling_players = players_data[~players_data['nflId'].isin(tackle_nfl_ids)]\n",
    "\n",
    "# Now, 'tackling_players' contains players involved in a tackle,\n",
    "# and 'non_tackling_players' contains players not involved in a tackle.\n",
    "print(len(tackling_players))\n",
    "print(len(non_tackling_players))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering tracking data for week 1...Filtering tracking data for week 2...\n",
      "\n",
      "Filtering tracking data for week 3...\n",
      "Filtering tracking data for week 4...\n",
      "Filtered tracking data for week 2 saved.\n",
      "Filtering tracking data for week 5...\n",
      "Filtered tracking data for week 3 saved.\n",
      "Filtering tracking data for week 6...\n",
      "Filtered tracking data for week 1 saved.\n",
      "Filtering tracking data for week 7...\n",
      "Filtered tracking data for week 4 saved.\n",
      "Filtering tracking data for week 8...\n",
      "Filtered tracking data for week 6 saved.\n",
      "Filtering tracking data for week 9...\n",
      "Filtered tracking data for week 5 saved.\n",
      "Filtered tracking data for week 7 saved.\n",
      "Filtered tracking data for week 8 saved.\n",
      "Filtered tracking data for week 9 saved.\n",
      "Filtering completed for all weeks.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "import os\n",
    "\n",
    "# Load the tackling players' NFL IDs into a list\n",
    "tackling_players_nfl_ids = list(tackling_players['nflId'])\n",
    "\n",
    "# Define the list of columns to keep\n",
    "columns_to_keep = ['gameId', 'playId', 'nflId', 'x', 'y', 's', 'a', 'dir', 'time']\n",
    "\n",
    "# Define a function to filter tracking data for a single week\n",
    "def filter_tracking_data(week_num):\n",
    "    tracking_file = f'data/tracking_week_{week_num}.csv'\n",
    "    \n",
    "    if os.path.exists(tracking_file):\n",
    "        print(f'Filtering tracking data for week {week_num}...')\n",
    "        \n",
    "        # Load the tracking data for the week into a DataFrame\n",
    "        tracking_data = pd.read_csv(tracking_file)\n",
    "        \n",
    "        # Filter the tracking data to include only relevant NFL IDs\n",
    "        filtered_tracking_data = tracking_data[tracking_data['nflId'].isin(tackling_players_nfl_ids)]\n",
    "        \n",
    "        # Keep only the specified columns\n",
    "        filtered_tracking_data = filtered_tracking_data[columns_to_keep]\n",
    "        \n",
    "        # Save the filtered tracking data to a new CSV file\n",
    "        filtered_tracking_data.to_csv(f'data/filtered_tracking_week_{week_num}.csv', index=False)\n",
    "        \n",
    "        print(f'Filtered tracking data for week {week_num} saved.')\n",
    "    else:\n",
    "        print(f'Tracking data file for week {week_num} not found.')\n",
    "\n",
    "# Use multi-threading to process each week concurrently\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    # Process weeks 1 to 9\n",
    "    executor.map(filter_tracking_data, range(1, 10))\n",
    "\n",
    "print('Filtering completed for all weeks.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered tracking data saved for week 1.\n",
      "Filtered tracking data saved for week 2.\n",
      "Filtered tracking data saved for week 3.\n",
      "Filtered tracking data saved for week 4.\n",
      "Filtered tracking data saved for week 5.\n",
      "Filtered tracking data saved for week 6.\n",
      "Filtered tracking data saved for week 7.\n",
      "Filtered tracking data saved for week 8.\n",
      "Filtered tracking data saved for week 9.\n",
      "Filtering completed for all weeks.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the list of columns to keep\n",
    "columns_to_keep = ['gameId', 'playId', 'nflId', 'x', 'y', 's', 'a', 'dir']\n",
    "\n",
    "# Create a directory to store the filtered tracking data\n",
    "filtered_tracking_dir = 'filtered_tracking_data'\n",
    "if not os.path.exists(filtered_tracking_dir):\n",
    "    os.makedirs(filtered_tracking_dir)\n",
    "\n",
    "# Loop through each week (from 1 to 9)\n",
    "for week_num in range(1, 10):\n",
    "    input_file = f'data/filtered_tracking_week_{week_num}.csv'\n",
    "    output_file = f'{filtered_tracking_dir}/filtered_tracking_week_{week_num}.csv'\n",
    "\n",
    "    if os.path.exists(input_file):\n",
    "        # Load the filtered tracking data for the week into a DataFrame\n",
    "        tracking_data = pd.read_csv(input_file)\n",
    "\n",
    "        # Filter and keep only the specified columns\n",
    "        filtered_tracking_data = tracking_data[columns_to_keep]\n",
    "\n",
    "        # Save the filtered tracking data to a new CSV file\n",
    "        filtered_tracking_data.to_csv(output_file, index=False)\n",
    "        \n",
    "        print(f'Filtered tracking data saved for week {week_num}.')\n",
    "    else:\n",
    "        print(f'Filtered tracking data file for week {week_num} not found.')\n",
    "\n",
    "print('Filtering completed for all weeks.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The smallest time in filtered_tracking_week_1.csv is: 2022-09-08 20:24:05.200000\n"
     ]
    }
   ],
   "source": [
    "#find smallest time in filætered tracking data\n",
    "import pandas as pd\n",
    "# Read the filtered tracking data for week 1 into a DataFrame\n",
    "filtered_tracking_data = pd.read_csv('data/filtered_tracking_week_1.csv')\n",
    "\n",
    "# Find the smallest time value in the DataFrame\n",
    "smallest_time = filtered_tracking_data['time'].min()\n",
    "\n",
    "# Print the smallest time\n",
    "print(f\"The smallest time in filtered_tracking_week_1.csv is: {smallest_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        gameId  playId  ballCarrierId  quarter gameClock\n",
      "1   2022091103    3126          52457        4      7:38\n",
      "2   2022091111    1148          42547        2      8:57\n",
      "3   2022100212    2007          46461        3     13:12\n",
      "7   2022102310      56          46377        1     15:00\n",
      "13  2022103010    3127          47853        4      5:35\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the plays data into a DataFrame\n",
    "plays_data = pd.read_csv('data/plays.csv')\n",
    "\n",
    "# Extract unique playId values from the 'result' DataFrame\n",
    "unique_playIds = result['playId'].unique()\n",
    "\n",
    "# Filter the plays data to include only playIds found in 'unique_playIds'\n",
    "filtered_plays_data = plays_data[plays_data['playId'].isin(unique_playIds)]\n",
    "\n",
    "# Keep only the specified columns\n",
    "filtered_plays_data = filtered_plays_data[['gameId', 'playId', 'ballCarrierId', 'quarter', 'gameClock']]\n",
    "\n",
    "# Now, 'filtered_plays_data' contains only the specified columns for plays with playIds found in 'result'\n",
    "print(filtered_plays_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the filtered plays data into a DataFrame\n",
    "\n",
    "\n",
    "# Load the games data into a DataFrame\n",
    "games_data = pd.read_csv('data/games.csv')\n",
    "\n",
    "# Define a function to convert gameClock to Eastern Time\n",
    "def convert_to_eastern_time(row):\n",
    "    # Find the corresponding gameId in games_data\n",
    "    game_info = games_data[games_data['gameId'] == row['gameId']]\n",
    "    \n",
    "    if not game_info.empty:\n",
    "        # Extract the gameDate and gameTimeEastern from game_info\n",
    "        game_date = game_info.iloc[0]['gameDate']\n",
    "        game_time_eastern = game_info.iloc[0]['gameTimeEastern']\n",
    "        \n",
    "        # Combine gameDate and gameTimeEastern into a datetime string\n",
    "        datetime_str = f\"{game_date} {game_time_eastern}\"\n",
    "        \n",
    "        # Parse the datetime string\n",
    "        game_datetime = pd.to_datetime(datetime_str, format='%m/%d/%Y %H:%M:%S')\n",
    "        \n",
    "        # Split the gameClock to extract minutes and seconds\n",
    "        minutes, seconds = map(int, row['gameClock'].split(':'))\n",
    "        \n",
    "        # Calculate the time difference based on the quarter\n",
    "        if row['quarter'] in [1, 3]:\n",
    "            game_datetime += pd.to_timedelta((15 - minutes) * 60 + (60 - seconds), unit='s')\n",
    "        elif row['quarter'] == 2:\n",
    "            game_datetime += pd.to_timedelta((30 - minutes) * 60 + (60 - seconds), unit='s')\n",
    "        else:  # Quarter 4\n",
    "            game_datetime += pd.to_timedelta((45 - minutes) * 60 + (60 - seconds), unit='s')\n",
    "        \n",
    "        return game_datetime.strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Apply the conversion function to create a new column 'easternTime'\n",
    "filtered_plays_data['easternTime'] = filtered_plays_data.apply(convert_to_eastern_time, axis=1)\n",
    "\n",
    "# Now, 'filtered_plays_data' contains the 'easternTime' column with the converted time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        gameId  playId  ballCarrierId  quarter gameClock  \\\n",
      "1   2022091103    3126          52457        4      7:38   \n",
      "2   2022091111    1148          42547        2      8:57   \n",
      "3   2022100212    2007          46461        3     13:12   \n",
      "7   2022102310      56          46377        1     15:00   \n",
      "13  2022103010    3127          47853        4      5:35   \n",
      "\n",
      "                   easternTime  \n",
      "1   2022-09-11 13:38:22.000000  \n",
      "2   2022-09-11 16:47:03.000000  \n",
      "3   2022-10-02 16:27:48.000000  \n",
      "7   2022-10-23 16:26:00.000000  \n",
      "13  2022-10-30 17:05:25.000000  \n"
     ]
    }
   ],
   "source": [
    "print (filtered_plays_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          gameId  playId  ballCarrierId  quarter gameClock  \\\n",
      "4889  2022090800      56          42489        1     15:00   \n",
      "2819  2022090800      80          46076        1     14:29   \n",
      "7700  2022090800     101          47857        1     13:54   \n",
      "7879  2022090800     191          52494        1     11:20   \n",
      "1363  2022090800     236          52536        1     10:03   \n",
      "\n",
      "                     easternTime  \n",
      "4889  2022-09-08 20:21:00.000000  \n",
      "2819  2022-09-08 20:21:31.000000  \n",
      "7700  2022-09-08 20:22:06.000000  \n",
      "7879  2022-09-08 20:24:40.000000  \n",
      "1363  2022-09-08 20:25:57.000000  \n"
     ]
    }
   ],
   "source": [
    "#sort filtered_plays by gameid playid and quarter\n",
    "filtered_plays_data.sort_values(by=['gameId', 'playId', 'quarter'], inplace=True)\n",
    "print(filtered_plays_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing tracking data for week 1...\n",
      "Processing completed for week 1.\n",
      "Processing tracking data for week 2...\n",
      "Processing completed for week 2.\n",
      "Processing tracking data for week 3...\n",
      "Processing completed for week 3.\n",
      "Processing tracking data for week 4...\n",
      "Processing completed for week 4.\n",
      "Processing tracking data for week 5...\n",
      "Processing completed for week 5.\n",
      "Processing tracking data for week 6...\n",
      "Processing completed for week 6.\n",
      "Processing tracking data for week 7...\n",
      "Processing completed for week 7.\n",
      "Processing tracking data for week 8...\n",
      "Processing completed for week 8.\n",
      "Processing tracking data for week 9...\n",
      "Processing completed for week 9.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the plays data into a DataFrame\n",
    "plays_data = pd.read_csv('data/plays.csv')\n",
    "\n",
    "# Load the tackles data into a DataFrame\n",
    "tackles_data = pd.read_csv('data/tackles.csv')\n",
    "\n",
    "# Define a function to process tracking data for a given week\n",
    "def process_tracking_data(week_num):\n",
    "    # Load the tracking data for the week into a DataFrame\n",
    "    tracking_file = f'data/tracking_week_{week_num}.csv'\n",
    "    \n",
    "    if os.path.exists(tracking_file):\n",
    "        print(f'Processing tracking data for week {week_num}...')\n",
    "        tracking_data = pd.read_csv(tracking_file)\n",
    "        \n",
    "        # Step 1: Find rows with \"out_of_bounds\" in tracking data\n",
    "        out_of_bounds_rows = tracking_data[tracking_data['event'] == 'out_of_bounds']\n",
    "        \n",
    "        # Step 2: Match the corresponding play using gameId and playId\n",
    "        merged_data = pd.merge(out_of_bounds_rows, plays_data, on=['gameId', 'playId'], how='inner')\n",
    "        \n",
    "        # Step 3: Find the matching tackle information (if it exists)\n",
    "        merged_data_with_tackle = pd.merge(merged_data, tackles_data, on=['gameId', 'playId'], how='left')\n",
    "        \n",
    "        # Now, you can further analyze or save the data for this week as needed\n",
    "        \n",
    "        print(f'Processing completed for week {week_num}.')\n",
    "    else:\n",
    "        print(f'Tracking data file for week {week_num} not found.')\n",
    "\n",
    "# Use a loop to process each week's tracking data\n",
    "for week_num in range(1, 10):\n",
    "    process_tracking_data(week_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing tracking data for week 1...\n",
      "Processing completed for week 1.\n",
      "Processing tracking data for week 2...\n",
      "Processing completed for week 2.\n",
      "Processing tracking data for week 3...\n",
      "Processing completed for week 3.\n",
      "Processing tracking data for week 4...\n",
      "Processing completed for week 4.\n",
      "Processing tracking data for week 5...\n",
      "Processing completed for week 5.\n",
      "Processing tracking data for week 6...\n",
      "Processing completed for week 6.\n",
      "Processing tracking data for week 7...\n",
      "Processing completed for week 7.\n",
      "Processing tracking data for week 8...\n",
      "Processing completed for week 8.\n",
      "Processing tracking data for week 9...\n",
      "Processing completed for week 9.\n",
      "Total \"out_of_bounds\" events with a tackle: 51749\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the plays data into a DataFrame\n",
    "plays_data = pd.read_csv('data/plays.csv')\n",
    "\n",
    "# Load the tackles data into a DataFrame\n",
    "tackles_data = pd.read_csv('data/tackles.csv')\n",
    "\n",
    "# Initialize a global counter for out_of_bounds events with a tackle\n",
    "out_of_bounds_with_tackle_count = 0\n",
    "\n",
    "# Define a function to process tracking data for a given week\n",
    "def process_tracking_data(week_num):\n",
    "    global out_of_bounds_with_tackle_count  # Declare the variable as global\n",
    "    \n",
    "    # Load the tracking data for the week into a DataFrame\n",
    "    tracking_file = f'data/tracking_week_{week_num}.csv'\n",
    "    \n",
    "    if os.path.exists(tracking_file):\n",
    "        print(f'Processing tracking data for week {week_num}...')\n",
    "        tracking_data = pd.read_csv(tracking_file)\n",
    "        \n",
    "        # Step 1: Find rows with \"out_of_bounds\" in tracking data\n",
    "        out_of_bounds_rows = tracking_data[tracking_data['event'] == 'out_of_bounds']\n",
    "        \n",
    "        # Step 2: Match the corresponding play using gameId and playId\n",
    "        merged_data = pd.merge(out_of_bounds_rows, plays_data, on=['gameId', 'playId'], how='inner')\n",
    "        \n",
    "        # Step 3: Find the matching tackle information (if it exists)\n",
    "        merged_data_with_tackle = pd.merge(merged_data, tackles_data, on=['gameId', 'playId'], how='left')\n",
    "        \n",
    "        # Count the occurrences of \"out_of_bounds\" events with a tackle\n",
    "        out_of_bounds_with_tackle_count += len(merged_data_with_tackle)\n",
    "        \n",
    "        print(f'Processing completed for week {week_num}.')\n",
    "    else:\n",
    "        print(f'Tracking data file for week {week_num} not found.')\n",
    "\n",
    "# Use a loop to process each week's tracking data\n",
    "for week_num in range(1, 10):\n",
    "    process_tracking_data(week_num)\n",
    "\n",
    "# Print the total count of \"out_of_bounds\" events with a tackle\n",
    "print(f'Total \"out_of_bounds\" events with a tackle: {out_of_bounds_with_tackle_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing tracking data for week 1...\n",
      "Processing completed for week 1.\n",
      "Processing tracking data for week 2...\n",
      "Processing completed for week 2.\n",
      "Processing tracking data for week 3...\n",
      "Processing completed for week 3.\n",
      "Processing tracking data for week 4...\n",
      "Processing completed for week 4.\n",
      "Processing tracking data for week 5...\n",
      "Processing completed for week 5.\n",
      "Processing tracking data for week 6...\n",
      "Processing completed for week 6.\n",
      "Processing tracking data for week 7...\n",
      "Processing completed for week 7.\n",
      "Processing tracking data for week 8...\n",
      "Processing completed for week 8.\n",
      "Processing tracking data for week 9...\n",
      "Processing completed for week 9.\n",
      "Total \"out_of_bounds\" events across weeks 1 to 9: 41629\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Initialize a global counter for out_of_bounds events\n",
    "out_of_bounds_count = 0\n",
    "\n",
    "# Define a function to process tracking data for a given week\n",
    "def process_tracking_data(week_num):\n",
    "    global out_of_bounds_count  # Declare the variable as global\n",
    "    \n",
    "    # Load the tracking data for the week into a DataFrame\n",
    "    tracking_file = f'data/tracking_week_{week_num}.csv'\n",
    "    \n",
    "    if os.path.exists(tracking_file):\n",
    "        print(f'Processing tracking data for week {week_num}...')\n",
    "        tracking_data = pd.read_csv(tracking_file)\n",
    "        \n",
    "        # Step 1: Count occurrences of \"out_of_bounds\" in the 'event' column\n",
    "        out_of_bounds_week_count = len(tracking_data[tracking_data['event'] == 'out_of_bounds'])\n",
    "        \n",
    "        # Accumulate the count to the global total\n",
    "        out_of_bounds_count += out_of_bounds_week_count\n",
    "        \n",
    "        print(f'Processing completed for week {week_num}.')\n",
    "    else:\n",
    "        print(f'Tracking data file for week {week_num} not found.')\n",
    "\n",
    "# Use a loop to process each week's tracking data\n",
    "for week_num in range(1, 10):\n",
    "    process_tracking_data(week_num)\n",
    "\n",
    "# Print the total count of \"out_of_bounds\" events\n",
    "print(f'Total \"out_of_bounds\" events across weeks 1 to 9: {out_of_bounds_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of combos with out_of_bounds: 2\n",
      "Number of combos without out_of_bounds: 128\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the tackles data into a DataFrame\n",
    "tackles_data = pd.read_csv('data/tackles.csv')\n",
    "\n",
    "# Initialize counters\n",
    "tackle_count = 0\n",
    "missed_tackle_count = 0\n",
    "missed_tackle_with_out_of_bounds_count = 0\n",
    "\n",
    "# Step 1: Identify missed tackles\n",
    "missed_tackle_plays = tackles_data.groupby(['playId', 'gameId']).filter(lambda x: x['pff_missedTackle'].sum() == len(x))\n",
    "\n",
    "# Step 2: Check if missed tackles correspond to \"out_of_bounds\" events\n",
    "for idx, combo in missed_tackle_plays.groupby(['playId', 'gameId']).size().reset_index().iterrows():\n",
    "    playId = combo['playId']\n",
    "    gameId = combo['gameId']\n",
    "    \n",
    "    # Search tracking data for \"out_of_bounds\" events for the same player\n",
    "    tracking_data_file = f'data/tracking_week_{week_num}.csv'  # Replace week_num with the appropriate week\n",
    "    tracking_data = pd.read_csv(tracking_data_file)\n",
    "    \n",
    "    player_events = tracking_data[(tracking_data['playId'] == playId) & (tracking_data['gameId'] == gameId) & (tracking_data['event'] == 'out_of_bounds')]\n",
    "    \n",
    "    if not player_events.empty:\n",
    "        missed_tackle_with_out_of_bounds_count += 1\n",
    "    else:\n",
    "        missed_tackle_count += 1\n",
    "\n",
    "# Step 3: Analyze the results\n",
    "tackle_count = len(tackles_data) - missed_tackle_count  # Total tackles\n",
    "print(f'Total Tackles: {tackle_count}')\n",
    "print(f'Total Missed Tackles: {missed_tackle_count}')\n",
    "print(f'Missed Tackles with Out of Bounds: {missed_tackle_with_out_of_bounds_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tackles: 16268\n",
      "Total Missed Tackles: 1158\n",
      "Missed Tackles with Out of Bounds: 12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the tackles data into a DataFrame\n",
    "tackles_data = pd.read_csv('data/tackles.csv')\n",
    "\n",
    "# Initialize counters\n",
    "tackle_count = 0\n",
    "missed_tackle_count = 0\n",
    "missed_tackle_with_out_of_bounds_count = 0\n",
    "\n",
    "# Iterate through weeks 1 to 9\n",
    "for week_num in range(1, 10):\n",
    "    # Step 1: Identify missed tackles\n",
    "    missed_tackle_plays = tackles_data.groupby(['playId', 'gameId']).filter(lambda x: x['pff_missedTackle'].sum() == len(x))\n",
    "\n",
    "    # Step 2: Check if missed tackles correspond to \"out_of_bounds\" events\n",
    "    for idx, combo in missed_tackle_plays.groupby(['playId', 'gameId']).size().reset_index().iterrows():\n",
    "        playId = combo['playId']\n",
    "        gameId = combo['gameId']\n",
    "\n",
    "        # Search tracking data for \"out_of_bounds\" events for the same player\n",
    "        tracking_data_file = f'data/tracking_week_{week_num}.csv'\n",
    "        tracking_data = pd.read_csv(tracking_data_file)\n",
    "\n",
    "        player_events = tracking_data[(tracking_data['playId'] == playId) & (tracking_data['gameId'] == gameId) & (tracking_data['event'] == 'out_of_bounds')]\n",
    "\n",
    "        if not player_events.empty:\n",
    "            missed_tackle_with_out_of_bounds_count += 1\n",
    "        else:\n",
    "            missed_tackle_count += 1\n",
    "\n",
    "# Step 3: Analyze the results\n",
    "tackle_count = len(tackles_data) - missed_tackle_count  # Total tackles\n",
    "print(f'Total Tackles: {tackle_count}')\n",
    "print(f'Total Missed Tackles: {missed_tackle_count}')\n",
    "print(f'Missed Tackles with Out of Bounds: {missed_tackle_with_out_of_bounds_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tackles = pd.read_csv('data/tackles.csv')\n",
    "# Assuming you have already loaded the \"tackles\" DataFrame\n",
    "# Filter the DataFrame to include rows with \"tackle\" and \"pff_missedTackle\" but not \"assist\" or \"forcedFumble\"\n",
    "filtered_tackles = tackles[~((tackles['tackle'] == 1) & (tackles['pff_missedTackle'] == 1))]\n",
    "filtred_tackles = filtered_tackles[~((filtered_tackles['assist'] == 1) & (filtered_tackles['forcedFumble'] == 1))]\n",
    "# Now \"filtered_tackles\" contains the rows meeting your criteria\n",
    "#create csv file with filtered tackles\n",
    "filtered_tackles.to_csv('data/filtered_tackles.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          gameId  playId  nflId  tackle  assist  forcedFumble  \\\n",
      "219   2022091805    2361  52444       1       0             0   \n",
      "455   2022091102     189  52571       1       0             0   \n",
      "696   2022091105    2742  53450       1       0             0   \n",
      "935   2022091110     750  52546       1       0             0   \n",
      "1213  2022091200    3723  52435       1       0             0   \n",
      "\n",
      "      pff_missedTackle  \n",
      "219                  1  \n",
      "455                  1  \n",
      "696                  1  \n",
      "935                  1  \n",
      "1213                 1  \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
